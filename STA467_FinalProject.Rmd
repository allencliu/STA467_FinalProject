---
title: "STA467 Final Project"
author: "Allen Liu"
date: "2024-04-03"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(tidyverse)
library(MASS)
library(splines)
library(glmnet)
library(randomForest)
library(GGally)
library(ggplot2)
library(corrplot)
library(MLeval)
```

# I. Introduction
This wine data set presents an intriguing opportunity for predictive modeling, focusing on physicochemical properties and sensory data of the red wine variants of the Portuguese "Vinho Verde" wine. Sourced from the UCI machine learning repository and detailed by [Cortez et al., 2009], this data set offers a classification task: determining wine quality based on a 0 to 10 scale.

Logistic regression, linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), regularization techniques (Lasso, Ridge, Elastic Net), and random forest will be used to analyze this data set. Each model is tuned and evaluated using repeated cross-validation techniques for robustness and accuracy.

By setting a binary classification threshold for wine quality and leveraging advanced modeling approaches, the goal is to uncover the physiochemical attributes that differentiate red wines. The focus of this analysis extends beyond prediction; the aim is to understand the interaction of variables contributing to wine quality perception, thereby contributing to enology and predictive modeling.


# II. Exploratory Data Analysis (EDA)

```{r, echo=FALSE}
wine <- read.csv("winequality-red.csv", header=T, stringsAsFactors=F)
# head(wine)
```

```{r, echo=FALSE}
# Classify wines >= 7 as good (1) and not good < 7 (0)
wine$quality <- as.factor(ifelse(wine$quality >= 7, 'good', 'not_good'))
head(wine)
```
As part of the exploratory data analysis (EDA), the 'quality' variable will be modified into a binary format. This modification involves categorizing wines into two distinct groups: 'good' and 'not good.' The rationale behind this transformation is to simplify the analysis and modeling tasks by focusing on whether a wine is considered 'good' rather than its specific quality score.

An arbitrary cutoff point will be set at a quality score of 7 or higher, classifying wines with scores above this threshold as 'good' and the remaining wines as 'not good.' This decision is informed by domain knowledge and prior research indicating that wines with higher quality scores are generally perceived more favorably by consumers.

By converting the 'quality' variable into a binary format, it facilitates the identification of key factors that contribute to the perception of wine quality. Throughout this analysis, the binary 'quality' variable will be referred to, investigating the factors that distinguish 'good' wines from 'not good' ones, providing valuable insights for enology and predictive modeling tasks.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ggpairs(wine)
```

From the ggpairs plot, some of the predictors exhibit right-skewed or non-normally distributed patterns. This observation is particularly notable in variables such as 'residual sugar,' 'chlorides,' 'free sulfur dioxide,' 'total sulfur dioxide,' and 'sulphates.' The right-skewed nature of these variables indicates a higher frequency of lower values with a tail stretching towards higher values. This skewness can impact the performance of certain statistical models that assume a normal distribution of data, potentially leading to biased estimates or inaccurate predictions. Therefore, the skewness in these predictors will be addressed through modeling techniques that can handle non-normal data effectively. This ensures that the modeling process accounts for the distributional characteristics of the predictors, ultimately enhancing the accuracy and reliability of the predictive models.

```{r, echo=FALSE}
# cor(wine[,-12])
corrplot(cor(wine[,-12]))
```

**Fixed Acidity vs. Citric Acid**: There is a strong positive correlation (approximately 0.67) between fixed acidity and citric acid. This indicates that wines with higher fixed acidity tend to have higher levels of citric acid as well.

**Fixed Acidity vs. Density**: Fixed acidity also shows a moderately positive correlation (around 0.67) with density. Wines with higher fixed acidity may thus tend to have higher densities.

**Volatile Acidity vs. Citric Acid**: There is a moderate negative correlation (about -0.55) between volatile acidity and citric acid. Wines with higher levels of volatile acidity are likely to have lower levels of citric acid.

**pH vs. Fixed Acidity and Citric Acid**: pH exhibits a strong negative correlation with fixed acidity (around -0.68) and a moderate negative correlation with citric acid (about -0.54). This suggests that wines with higher fixed acidity and lower citric acid content tend to have lower pH levels.

**Alcohol vs. Density**: Alcohol content shows a moderate negative correlation (approximately -0.50) with density. Wines with higher alcohol content may have lower densities.

It's important to note that while certain variables may exhibit strong correlations, the models used for analysis will still incorporate the full predictor set initially. This approach ensures that the models consider all available information and relationships among the predictors before any feature selection or removal is performed. Later in the analysis, the impact of removing predictors based on correlations or other criteria will be explored, and the performance of models with and without certain predictors will be compared (**refer to Appendix B**). This comparative analysis will provide insights into the importance of individual predictors and their contribution to predictive modeling.

# III. Modeling Approach, Building, and Evaluation

The modeling approach employed for predicting wine quality involved utilizing a variety of machine learning algorithms. Specifically, the following models were trained and evaluated:

**1. Logistic Regression:**

  + The logistic regression model was trained using the "glm" method with repeated cross-validation (CV) performed using 10 folds and 10 repeats. The data was preprocessed by centering and scaling.
 
**2. Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA):**

  + LDA and QDA models were trained using their respective methods with the same repeated CV setup and preprocessing as logistic regression.
 
**3. Lasso, Ridge, and Elastic Net Regression:**

  + Lasso, Ridge, and Elastic Net models were trained using the "glmnet" method with repeated CV and preprocessing similar to the other models. Different regularization parameters (alpha and lambda) were tuned to optimize model performance.
 
**4. Random Forest:**

  + The Random Forest model was trained using the "rf" method with repeated CV, tuning the number of variables randomly sampled as candidates at each split (mtry) and setting the number of trees (ntree) to 100.

```{r, echo=FALSE}
set.seed(05122024)
# Logistic Regression
wine_logit <- train(quality ~ .,
                     data = wine,
                     method = "glm",
                     trControl = trainControl(method = "repeatedcv", 
                                              number = 10, 
                                              repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))

```

```{r, echo=FALSE}
set.seed(05122024)
# LDA
wine_lda <- train(quality ~ .,
                     data = wine,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                              number = 10, 
                                              repeats = 10, 
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))

# QDA
wine_qda <- train(quality ~ .,
                     data = wine,
                     method = "qda",
                     trControl = trainControl(method = "repeatedcv", 
                                              number = 10, 
                                              repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))
```

```{r, echo=FALSE}
set.seed(05122024)
# Lasso/Ridge/Elastic

# Lasso
wine_lasso <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                           number = 10, 
                                           repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=1,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))


# Ridge
wine_ridge <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                           number = 10, 
                                           repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=0,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_elastic <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                           number = 10, 
                                           repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=seq(0,0.1,by=0.01),
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

```

```{r, echo=FALSE}
set.seed(05122024)
# Decision Tree
wine_tree <- train(quality ~ .,
                   data=wine,
                   method="rf",
                   trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                          savePredictions = TRUE, 
                                          summaryFunction = twoClassSummary, 
                                          classProbs = TRUE),
                   metric = "ROC",
                   tuneGrid=data.frame(mtry=seq(1,11,by=1)),
                   ntree=100)
```

```{r, echo=FALSE}
models <- list(Logistic = wine_logit, LDA = wine_lda, QDA = wine_qda, Lasso = wine_lasso, Ridge = wine_ridge, Elastic = wine_elastic, "Random Forest" = wine_tree)
models <- models[order(names(models))]

evalm1 <- evalm(models, gnames = names(models), silent = TRUE, showplots = FALSE)

evalm1$roc

wine_results <- resamples(models)$values
summary(wine_results)
```


# IV. Results, Discussion, and Conclusion

## Results
**1. Model Performance**

The ROC curves reveal that the Random Forest model outperforms all others, demonstrating its superior fit for the wine data set. On the other hand, the Quadratic Discriminant Analysis (QDA) exhibits the lowest ROC curve, indicating comparatively weaker predictive performance. Among the remaining models, including Elastic Net, Lasso, LDA, Logistic Regression, and Ridge Regression, their ROC curves are closely clustered with negligible differences in performance. This suggests that while these models are competitive, the Random Forest model stands out as the most effective choice for accurately discriminating between wine quality.

```{r, echo=FALSE}
# varImp(wine_tree, scale = F)
plot(varImp(wine_tree, scale = F))
```

**2. Feature Importance Analysis**

The variable importance analysis reveals key insights into the importance of physicochemical features in predicting wine quality. Among the top-ranking features, alcohol is the most influential predictor with a high importance score of 57.95. This is followed closely by sulphates (44.12), volatile acidity (38.70), density (36.52), and citric acid (34.98). These features significantly contribute to the Random Forest model's ability to accurately classify wines as good or not good.

## Discussion
**1. Interpretation of Feature Importance**

The high importance of alcohol, sulphates, volatile acidity, density, and citric acid highlights their crucial role in determining wine quality. These features likely capture aspects related to flavor profile, acidity levels, and alcohol content, which are known factors influencing wine quality (Understanding Acidity in Wine, 2024). 

**2. Specificity and Sensitivity**
Specificity and sensitivity are vital metrics in classification tasks. Specificity measures the ability of a model to correctly identify negative instances, indicating how well it avoids false positives. On the other hand, sensitivity quantifies the model's ability to detect positive instances accurately without missing actual positive cases, i.e. how well it avoids false negatives.

**3. Across the models tested:**
Random Forest exhibited a high sensitivity of up to 0.77, indicating its effectiveness in correctly identifying positive wine quality instances.
Specificity values were generally high across models, with Random Forest showing notable performance in correctly identifying negative instances. Sensitivity values, on the other hand, were generally low across models.

## Conclusion
**1. Key Findings**

The Random Forest model, driven by key features such as alcohol, sulphates, volatile acidity, density, and citric acid, emerged as the top-performing model for wine quality prediction. Understanding the importance of these features provides important insights for wine producers and industry stakeholders.

In analyzing the low sensitivity values observed across some models, it becomes apparent that these models are better at predicting wines of lower quality (mediocre to low quality) compared to identifying wines of high quality. This phenomenon suggests that the models may excel at detecting negative instances (e.g., poor-quality wines) but struggle to identify positive instances (e.g., good-quality wines) with the same level of accuracy. One potential factor contributing to this imbalance in predictive performance is the nature of the dataset itself, which may be skewed towards containing more instances of mediocre to low-quality wines than instances of high-quality wines. This imbalance can lead to a higher emphasis on learning patterns associated with negative instances, thereby affecting the models' ability to generalize well to positive instances.

**2. Practical Implications**

The variable importance analysis has practical implications for wine production and quality improvement strategies. Producers can use these insights to optimize wine formulations, enhance quality control measures, and tailor products to meet consumer preferences effectively.

In the context of wine quality assessment, where the focus often lies on identifying exceptional or high-quality wines, the low sensitivity values raise concerns about the models' effectiveness in precisely classifying such instances. Therefore, while the models may exhibit strong performance in terms of specificity (identifying non-good wines correctly), their lower sensitivity indicates a potential limitation in capturing and accurately predicting instances of high wine quality.


**3. Future Directions**

Future research endeavors may focus on exploring additional predictors or refining modeling techniques to further enhance predictive accuracy and deepen understanding of wine quality determinants. Future research into specific qualities of wines could look into tannin content, alcohol content, or acidity to narrow the scope (Dufourc, 2021).

Furthermore, addressing the challenge of having low sensitivities across the models requires strategies such as:

1. **Balancing the Dataset:** Collecting additional data or employing sampling techniques to balance the representation of different wine quality categories can help mitigate the effects of class imbalance.
2. **Adjusting Model Parameters:** Fine-tuning model parameters, such as adjusting class weights or using algorithms specifically designed for imbalanced datasets, can improve the models' sensitivity towards positive instances.
3. **Feature Engineering:** Incorporating domain knowledge and relevant features that better capture the characteristics of high-quality wines can enhance the models' ability to identify and predict such instances accurately.

By acknowledging and addressing these considerations, future iterations of the analysis can aim to improve the models' sensitivity specifically towards wines of high quality, aligning more closely with the practical objectives of wine quality assessment and decision-making in the industry.


# V. References and Appendices

## References
Dufourc, J. E., (2021). Wine tannins, saliva proteins and membrane lipids. Biochimica et Biophysica Acta (BBA)- Biomembranes. 1863(10). 
Understanding Acidicty in Wine. (2024). Understanding acidity in wine. Wine Folly. 2024.https://winefolly.com/deep-dive/understanding-acidity-in-wine/

UCI Machine Learning. “Red Wine Quality.” Kaggle, UCI, 27 Nov. 2017, www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009/data. 

## Appendix A: Sensitivity Improvement After Upsampling

```{r, echo=FALSE}
set.seed(05122024)
wine_logit_upsample <- train(quality ~ .,
                     data = wine,
                     method = "glm",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE,
                                              summaryFunction = twoClassSummary,
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))


wine_lda_upsample <- train(quality ~ .,
                     data = wine,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_qda_upsample <- train(quality ~ .,
                     data = wine,
                     method = "qda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_lasso_upsample <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=1,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_ridge_upsample <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=0,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_elastic_upsample <- train(quality ~ .,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=seq(0,0.1,by=0.01),
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))


wine_tree_upsample <- train(quality ~ .,
                   data=wine,
                   method="rf",
                   trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                          savePredictions = TRUE, 
                                          summaryFunction = twoClassSummary, 
                                          classProbs = TRUE,
                                          sampling = "up"), # Out-of-bag MSE
                   metric = "ROC",
                   tuneGrid=data.frame(mtry=seq(1,11,by=1)),
                   ntree=100)

models_upsample <- list(Logistic = wine_logit_upsample, LDA = wine_lda_upsample, QDA = wine_qda_upsample, Lasso = wine_lasso_upsample, Ridge = wine_ridge_upsample, Elastic = wine_elastic_upsample, "Random Forest" = wine_tree_upsample)
models_upsample <- models_upsample[order(names(models_upsample))]

evalm_upsample <- evalm(models_upsample, gnames = names(models_upsample), silent = TRUE, showplots = FALSE)

evalm_upsample$roc

wine_results_upsample <- resamples(models_upsample)$values
summary(wine_results_upsample)
```

### Before Upsampling

Before upsampling, the ROC curve values for most models indicated moderate to high performance, with minimal variation observed. Models like Ridge and Elastic showed slight improvements in their ROC curves after upsampling, indicating enhanced overall predictive power. However, the ROC curves of other models remained relatively stable, suggesting that their discriminatory ability between positive and negative instances did not significantly change.

### After Upsampling

Despite the limited improvement in ROC curve values post-upsampling, there was a substantial enhancement in sensitivity across various models. This improvement is particularly crucial as it signifies a significant boost in the models' ability to correctly identify positive instances, such as high-quality wines. The upsampling technique effectively addressed the imbalance in the dataset, allowing the models to better capture the minority class and make more accurate predictions for positive cases.

### Random Forest Exception

The Random Forest model, known for its ability to handle class imbalances effectively, showed consistent ROC curve values before and after upsampling. While the ROC curve did not demonstrate significant improvement, the model's sensitivity, although not dramatically enhanced, still benefited from the upsampling process. This indicates that Random Forest maintained its overall predictive power even with the dataset adjustments.

### Importance of Sensitivity Improvement

The notable improvement in sensitivity post-upsampling holds more significant practical implications than the modest changes in ROC curve values. Sensitivity directly influences the models' ability to detect positive instances accurately, aligning with the primary objective of identifying high-quality wines. Therefore, the sensitivity improvement observed after upsampling reinforces the effectiveness of this technique in improving model performance for imbalanced datasets.

### Considerations

While sensitivity improvement is a positive outcome of upsampling, it's essential to consider potential trade-offs and drawbacks. Upsampling can introduce biases or noise into the data, leading to overfitting or reduced generalization performance. Additionally, upsampling increases computational complexity and resource requirements, which may impact model scalability and real-time prediction capabilities. Hence, a balanced approach incorporating various validation techniques and performance metrics is crucial to evaluate model effectiveness comprehensively.

## Appendix B: Subset of Predictors Analysis

```{r, echo=FALSE}
set.seed(05122024)
wine_subset <- quality ~ alcohol + sulphates + volatile.acidity + density + citric.acid

wine_logit_subset <- train(wine_subset,
                     data = wine,
                     method = "glm",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE,
                                              summaryFunction = twoClassSummary,
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))


wine_lda_subset<- train(wine_subset,
                     data = wine,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_qda_subset <- train(wine_subset,
                     data = wine,
                     method = "qda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_lasso_subset <- train(wine_subset,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=1,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_ridge_subset <- train(wine_subset,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=0,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_elastic_subset <- train(wine_subset,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=seq(0,0.1,by=0.01),
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))


wine_tree_subset <- train(wine_subset,
                   data=wine,
                   method="rf",
                   trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                          savePredictions = TRUE, 
                                          summaryFunction = twoClassSummary, 
                                          classProbs = TRUE), # Out-of-bag MSE
                   metric = "ROC",
                   tuneGrid=data.frame(mtry=seq(1,5,by=1)),
                   ntree=100)

models_subset <- list(Logistic = wine_logit_subset, LDA = wine_lda_subset, QDA = wine_qda_subset, Lasso = wine_lasso_subset, Ridge = wine_ridge_subset, Elastic = wine_elastic_subset, "Random Forest" = wine_tree_subset)
models_subset <- models_subset[order(names(models_subset))]

evalm_subset <- evalm(models_subset, gnames = names(models_subset), silent = TRUE, showplots = FALSE)

evalm_subset$roc

wine_results_subset <- resamples(models_subset)$values
summary(wine_results_subset)
```




```{r, echo=FALSE}
set.seed(05122024)
wine_subset_upsample <- quality ~ alcohol + sulphates + volatile.acidity + density + citric.acid

wine_logit_subset_upsample <- train(wine_subset_upsample,
                     data = wine,
                     method = "glm",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE,
                                              summaryFunction = twoClassSummary,
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))


wine_lda_subset_upsample<- train(wine_subset_upsample,
                     data = wine,
                     method = "lda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_qda_subset_upsample <- train(wine_subset_upsample,
                     data = wine,
                     method = "qda",
                     trControl = trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                              savePredictions = TRUE, 
                                              summaryFunction = twoClassSummary, 
                                              classProbs = TRUE,
                                              sampling = "up"),
                     metric = "ROC",
                     preProcess=c("center","scale"))

wine_lasso_subset_upsample <- train(wine_subset_upsample,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=1,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_ridge_subset_upsample <- train(wine_subset_upsample,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=0,
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))

wine_elastic_subset_upsample <- train(wine_subset_upsample,
                    data = wine,
                    method="glmnet",
                    trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                           savePredictions = TRUE, 
                                           summaryFunction = twoClassSummary, 
                                           classProbs = TRUE,
                                           sampling = "up"),
                    metric = "ROC",
                    tuneGrid=expand.grid(alpha=seq(0,0.1,by=0.01),
                                         lambda=seq(0,0.1,by=0.01)),
                    preProcess=c("center","scale"))


wine_tree_subset_upsample <- train(wine_subset_upsample,
                   data=wine,
                   method="rf",
                   trControl=trainControl(method = "repeatedcv", 
                                          number = 10, 
                                          repeats = 10,
                                          savePredictions = TRUE, 
                                          summaryFunction = twoClassSummary, 
                                          classProbs = TRUE,
                                          sampling = "up"), # Out-of-bag MSE
                   metric = "ROC",
                   tuneGrid=data.frame(mtry=seq(1,5,by=1)),
                   ntree=100)

models_subset_upsample <- list(Logistic = wine_logit_subset_upsample, LDA = wine_lda_subset_upsample, QDA = wine_qda_subset_upsample, Lasso = wine_lasso_subset_upsample, Ridge = wine_ridge_subset_upsample, Elastic = wine_elastic_subset_upsample, "Random Forest" = wine_tree_subset_upsample)
models_subset_upsample <- models_subset_upsample[order(names(models_subset_upsample))]

evalm_subset_upsample <- evalm(models_subset_upsample, gnames = names(models_subset_upsample), silent = TRUE, showplots = FALSE)

evalm_subset_upsample$roc

wine_results_subset_upsample <- resamples(models_subset_upsample)$values
summary(wine_results_subset_upsample)
```

### Subset Selection Based on Variable Importance

A subset of predictors was selected based on their variable importance (varImp) scores, including alcohol, sulphates, volatile acidity, density, and citric acid. These predictors were deemed crucial for wine quality prediction based on their impact on model performance.

### Performance Metrics with Subset of Predictors

Upon analyzing the performance metrics using this subset of predictors, it was observed that the ROC curves slightly performed worse compared to using all predictors. Models like Elastic Net, Lasso, and Logistic Regression showed a minor decrease in ROC curve values, indicating a slight reduction in overall predictive power when limited to the subset.

### Sensitivity and Specificity Evaluation

Despite the decrease in ROC curve values, the subset of predictors exhibited improved sensitivity in most models, especially after upsampling. This improvement in sensitivity underscores the subset's effectiveness in capturing positive instances, which is crucial for identifying high-quality wines.

### Comparison with Full Predictor Set

It's noteworthy that the subset of predictors did not significantly outperform or match the performance achieved with the full set of predictors. In fact, the subset technically performed worse in terms of ROC curve values, suggesting that the exclusion of certain predictors might have led to a loss of predictive information.

### Upsampling Effect

When comparing the subset's performance with and without upsampling, sensitivity showed noticeable improvement post-upsampling, indicating that upsampling effectively addressed class imbalance issues and enhanced the models' ability to detect positive instances.

### Conclusion on Subset Performance

While the subset of predictors based on varImp scores showed promise in improving sensitivity, it also resulted in a slight decrease in ROC curve values. This highlights the trade-off between sensitivity and overall predictive power when using a limited set of predictors. For optimal performance, considering all relevant predictors in conjunction with appropriate data balancing techniques like upsampling may yield more robust and accurate predictive models for wine quality prediction.












